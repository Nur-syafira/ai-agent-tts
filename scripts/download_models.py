#!/usr/bin/env python3

"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π (ASR, LLM, TTS).
"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

import os
import subprocess
from huggingface_hub import snapshot_download
from dotenv import load_dotenv

load_dotenv()


def download_whisper_model():
    """–°–∫–∞—á–∏–≤–∞–µ—Ç faster-whisper –º–æ–¥–µ–ª—å (large-v3-turbo)."""
    print("üì• Downloading faster-whisper large-v3-turbo...")
    
    # faster-whisper —Å–∫–∞—á–∏–≤–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
    # –ù–æ –º–æ–∂–Ω–æ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∏—Ç—å —á–µ—Ä–µ–∑ CT2:
    try:
        from faster_whisper import WhisperModel
        
        model = WhisperModel(
            "large-v3-turbo",
            device="cuda",
            compute_type="int8_float16",
        )
        
        print("‚úÖ faster-whisper model ready")
        del model
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Failed to download faster-whisper: {e}")


def download_qwen_model():
    """–°–∫–∞—á–∏–≤–∞–µ—Ç Qwen2.5-14B-Instruct-AWQ."""
    print("üì• Downloading Qwen2.5-14B-Instruct-AWQ...")
    
    model_name = "Qwen/Qwen2.5-14B-Instruct-AWQ"
    cache_dir = os.path.expanduser("~/.cache/huggingface/hub")
    
    try:
        snapshot_download(
            repo_id=model_name,
            cache_dir=cache_dir,
            resume_download=True,
        )
        
        print(f"‚úÖ {model_name} downloaded")
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Failed to download Qwen: {e}")
        print("   Model will be downloaded automatically when vLLM starts")


def download_piper_model():
    """–°–∫–∞—á–∏–≤–∞–µ—Ç Piper TTS –º–æ–¥–µ–ª—å (—Ä—É—Å—Å–∫–∏–π)."""
    print("üì• Downloading Piper TTS model (ru_RU-dmitri-medium)...")
    
    models_dir = Path("models")
    models_dir.mkdir(exist_ok=True)
    
    model_url = "https://huggingface.co/rhasspy/piper-voices/resolve/main/ru/ru_RU/dmitri/medium/ru_RU-dmitri-medium.onnx"
    config_url = "https://huggingface.co/rhasspy/piper-voices/resolve/main/ru/ru_RU/dmitri/medium/ru_RU-dmitri-medium.onnx.json"
    
    model_path = models_dir / "ru_RU-dmitri-medium.onnx"
    config_path = models_dir / "ru_RU-dmitri-medium.onnx.json"
    
    if model_path.exists():
        print(f"   Model already exists: {model_path}")
    else:
        subprocess.run(["wget", "-O", str(model_path), model_url], check=True)
        print(f"‚úÖ Downloaded: {model_path}")
    
    if config_path.exists():
        print(f"   Config already exists: {config_path}")
    else:
        subprocess.run(["wget", "-O", str(config_path), config_url], check=True)
        print(f"‚úÖ Downloaded: {config_path}")


def download_silero_vad():
    """–°–∫–∞—á–∏–≤–∞–µ—Ç Silero VAD –º–æ–¥–µ–ª—å."""
    print("üì• Downloading Silero VAD...")
    
    try:
        import torch
        
        model, utils = torch.hub.load(
            repo_or_dir='snakers4/silero-vad',
            model='silero_vad',
            force_reload=False,
            onnx=True,
        )
        
        print("‚úÖ Silero VAD model ready")
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Failed to download Silero VAD: {e}")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    print("=" * 60)
    print("Sales Agent - Model Downloader")
    print("=" * 60)
    print()
    
    # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è –º–æ–¥–µ–ª–µ–π
    models_dir = Path("models")
    models_dir.mkdir(exist_ok=True)
    
    # –°–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª–∏
    download_whisper_model()
    print()
    
    download_qwen_model()
    print()
    
    download_piper_model()
    print()
    
    download_silero_vad()
    print()
    
    print("=" * 60)
    print("‚úÖ All models downloaded!")
    print("=" * 60)
    print()
    print("Note: Some models download automatically on first use.")
    print("      If you see warnings, it's okay - they'll download when needed.")


if __name__ == "__main__":
    main()

